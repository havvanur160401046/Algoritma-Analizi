{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projective Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from nltk.grammar import DependencyGrammar\n",
    ">>> from nltk.parse import (\n",
    "...     DependencyGraph,\n",
    "...     ProjectiveDependencyParser,\n",
    "...     NonprojectiveDependencyParser,\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_data = \"\"\"Pierre  NNP     2       NMOD\n",
    "... Vinken  NNP     8       SUB\n",
    "... ,       ,       2       P\n",
    "... 61      CD      5       NMOD\n",
    "... years   NNS     6       AMOD\n",
    "... old     JJ      2       NMOD\n",
    "... ,       ,       2       P\n",
    "... will    MD      0       ROOT\n",
    "... join    VB      8       VC\n",
    "... the     DT      11      NMOD\n",
    "... board   NN      9       OBJ\n",
    "... as      IN      9       VMOD\n",
    "... a       DT      15      NMOD\n",
    "... nonexecutive    JJ      15      NMOD\n",
    "... director        NN      12      PMOD\n",
    "... Nov.    NNP     9       VMOD\n",
    "... 29      CD      16      NMOD\n",
    "... .       .       9       VMOD\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(will\n",
      "  (Vinken Pierre , (old (years 61)) ,)\n",
      "  (join (board the) (as (director a nonexecutive)) (Nov. 29) .))\n"
     ]
    }
   ],
   "source": [
    ">>> dg = DependencyGraph(treebank_data)\n",
    ">>> dg.tree().pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(will, MD), SUB, (Vinken, NNP)\n",
      "(Vinken, NNP), NMOD, (Pierre, NNP)\n",
      "(Vinken, NNP), P, (,, ,)\n",
      "(Vinken, NNP), NMOD, (old, JJ)\n",
      "(old, JJ), AMOD, (years, NNS)\n",
      "(years, NNS), NMOD, (61, CD)\n",
      "(Vinken, NNP), P, (,, ,)\n",
      "(will, MD), VC, (join, VB)\n",
      "(join, VB), OBJ, (board, NN)\n",
      "(board, NN), NMOD, (the, DT)\n",
      "(join, VB), VMOD, (as, IN)\n",
      "(as, IN), PMOD, (director, NN)\n",
      "(director, NN), NMOD, (a, DT)\n",
      "(director, NN), NMOD, (nonexecutive, JJ)\n",
      "(join, VB), VMOD, (Nov., NNP)\n",
      "(Nov., NNP), NMOD, (29, CD)\n",
      "(join, VB), VMOD, (., .)\n"
     ]
    }
   ],
   "source": [
    ">>> for head, rel, dep in dg.triples():\n",
    "...     print(\n",
    "...         '({h[0]}, {h[1]}), {r}, ({d[0]}, {d[1]})'\n",
    "...         .format(h=head, r=rel, d=dep)\n",
    "...     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre\tNNP\t2\n",
      "Vinken\tNNP\t8\n",
      ",\t,\t2\n",
      "61\tCD\t5\n",
      "years\tNNS\t6\n",
      "old\tJJ\t2\n",
      ",\t,\t2\n",
      "will\tMD\t0\n",
      "join\tVB\t8\n",
      "the\tDT\t11\n",
      "board\tNN\t9\n",
      "as\tIN\t9\n",
      "a\tDT\t15\n",
      "nonexecutive\tJJ\t15\n",
      "director\tNN\t12\n",
      "Nov.\tNNP\t9\n",
      "29\tCD\t16\n",
      ".\t.\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> from nltk.corpus import dependency_treebank\n",
    ">>> t = dependency_treebank.parsed_sents()[0]\n",
    ">>> print(t.to_conll(3))  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 5 productions\n",
      "  'fell' -> 'price'\n",
      "  'fell' -> 'stock'\n",
      "  'price' -> 'of' 'the'\n",
      "  'of' -> 'stock'\n",
      "  'stock' -> 'the'\n"
     ]
    }
   ],
   "source": [
    ">>> grammar = DependencyGrammar.fromstring(\"\"\"\n",
    "... 'fell' -> 'price' | 'stock'\n",
    "... 'price' -> 'of' 'the'\n",
    "... 'of' -> 'stock'\n",
    "... 'stock' -> 'the'\n",
    "... \"\"\")\n",
    ">>> print(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> dp = ProjectiveDependencyParser(grammar)\n",
    ">>> for t in sorted(dp.parse(['I','love','you'])):\n",
    "...     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'taught' -> 'play'\n",
      "  'taught' -> 'man'\n",
      "  'man' -> 'the'\n",
      "  'play' -> 'golf'\n",
      "  'play' -> 'dog'\n",
      "  'play' -> 'to'\n",
      "  'dog' -> 'his'\n"
     ]
    }
   ],
   "source": [
    ">>> grammar = DependencyGrammar.fromstring(\"\"\"\n",
    "... 'taught' -> 'play' | 'man'\n",
    "... 'man' -> 'the'\n",
    "... 'play' -> 'golf' | 'dog' | 'to'\n",
    "... 'dog' -> 'his'\n",
    "... \"\"\")\n",
    ">>> print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taught\n"
     ]
    }
   ],
   "source": [
    ">>> dp = NonprojectiveDependencyParser(grammar)\n",
    ">>> g, = dp.parse(['the', 'man', 'taught', 'his', 'dog', 'to', 'play', 'golf'])\n",
    ">>> print(g.root['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download('state_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Projective Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text=\"the man taught his dog to play golf.\"\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(sample_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words=nltk.word_tokenize(i)\n",
    "            tagged=nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('man', 'NN'), ('taught', 'VBD'), ('his', 'PRP$'), ('dog', 'NN'), ('to', 'TO'), ('play', 'VB'), ('golf', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 the: []\n",
      "2 man: [1]\n",
      "3 taught: [2, 7]\n",
      "4 his: []\n",
      "5 dog: [4]\n",
      "6 to: []\n",
      "7 play: [5, 6, 8]\n",
      "8 golf: []\n"
     ]
    }
   ],
   "source": [
    ">>> for _, node in sorted(g.nodes.items()):\n",
    "...     if node['word'] is not None:\n",
    "...         print('{address} {word}: {d}'.format(d=node['deps'][''], **node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(taught (man the) (play (dog his) to golf))\n"
     ]
    }
   ],
   "source": [
    ">>> print(g.tree())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
